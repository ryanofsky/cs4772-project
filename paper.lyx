#LyX 1.5.1 created this file. For more info see http://www.lyx.org/
\lyxformat 276
\begin_document
\begin_header
\textclass article
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\paperfontsize default
\spacing single
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Dimensionality Reduction for Visualization of Text Similarity
\end_layout

\begin_layout Author
Russell Yanofsky (rey4@columbia.edu)
\end_layout

\begin_layout Date
December 13, 2007
\end_layout

\begin_layout Abstract
Techniques which express high dimensional data in a reduced number of dimensions
 while maintaining a useful amount of the information content of the original
 data are useful in data processing and analysis.
 This paper explores a somewhat unlikely application of dimensionality reduction
 techniques, applying techniques extremely well suited to visualization
 of data in two or three dimensions to a collection of text documents in
 English, which comprise a dataset that is not normally subject to 2D plotting
 and spatial analysis.
 The techniques used are Semidefinite Embedding (SDE) and Minimum Volume
 Embedding (MVE), which are both based on the general technique of Kernel
 Principal Components Analysis (KPCA).
 A preprocessed representation of text based on word frequency (disregarding
 word order) is used as input to these algorithms.
 This type of representation has been shown in other work to be effective
 at text categorization with kernel methods, although in this case, the
 results for visualization do not turn out to be very compelling, which
 may be due to the broad specification of the problem, or the nature of
 the data set used in the experiment.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Textual data is among the most ubiquitous forms of data that exist today,
 and automated means of processing it, performing operations such as searching,
 categorization, translation, and correction, have had great success and
 are seeing constant improvements.
 But the sheer amount of text data means that even after text is automatically
 searched, categorized, translated, and corrected, navigating it may not
 be easy.
 To help manage this problem, visualization techniques have the potential
 to be applied to provide an aide to human navigation.
 The idea behind visualization for this purpose would be to show documents
 which are related to each other as points clustered together in a two or
 three dimensional space.
\end_layout

\begin_layout Standard
Visual representations like this could have uses in certain types of research,
 for example, in helping to sort through large archives of historical documents.
 It could also be used on the Internet, as an accompaniment to search results
 and the automated recommendation systems commonly seen on book and movie
 websites.
 Finally, it might have use in the testing and development of other natural
 language processing algorithms, providing a tool to summarize large amounts
 of data, and to help evaluate experimental results.
\end_layout

\begin_layout Standard
Different visualization techniques have been applied in the past to the
 problem of document visualization, sometimes using ad-hoc methods.
 For example, one system 
\begin_inset LatexCommand cite
key "allan97interactive"

\end_inset

 uses a feedback method, positioning points representing documents in a
 space, and iteratively moving the documents in space closer together and
 farther apart based on similarity scores.
 Another system 
\begin_inset LatexCommand cite
key "carey-info"

\end_inset

 uses a visualization technique called sammon mapping to compute the low
 dimensional representation.
\end_layout

\begin_layout Standard
This paper presents the application of two more recent visualization techniques,
 Semidefinite Embedding (SDE) 
\begin_inset LatexCommand cite
key "000sde"

\end_inset

, and Minimum Volume Embedding (MVE) 
\begin_inset LatexCommand cite
key "000bshaw"

\end_inset

 to documentation visualization, and shows the results of applying these
 techniques to a small data set.
\end_layout

\begin_layout Section
PCA Dimensionality Reduction Techniques
\end_layout

\begin_layout Standard
The dimensionality reduction techniques used here can be understood in the
 context of Principal Component Analysis (PCA).
\end_layout

\begin_layout Section
String Kernels
\end_layout

\begin_layout Standard
Strings have kernels? You bet, and you wish you had a kernel, too.
\end_layout

\begin_layout Section
Experiment
\end_layout

\begin_layout Standard
So I took these things and did stuff.
 It didn't really work out the way I hoped.
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In conclusion, please stop reading.
\end_layout

\begin_layout Standard
\begin_inset LatexCommand bibtex
options "plain"
bibfiles "refs"

\end_inset


\end_layout

\end_body
\end_document
